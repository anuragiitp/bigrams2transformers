{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Simple Transformer Model for a-z Character Generation\n",
        "\n",
        "A simplified transformer implementation based for character-level text generation using only a-z vocabulary with block size of 8.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python version      : 3.12.6\n",
            "PyTorch version     : 2.7.1+cpu\n",
            "CUDA (torch) version: None\n",
            "cuDNN version       : None\n",
            "CUDA available      : False\n",
            "PyTorch version: 2.7.1+cpu\n",
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from dataclasses import dataclass\n",
        "import platform\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "torch.manual_seed(42)\n",
        "random.seed(42)\n",
        "\n",
        "print(\"Python version      :\", platform.python_version())\n",
        "print(\"PyTorch version     :\", torch.__version__)\n",
        "print(\"CUDA (torch) version:\", torch.version.cuda)\n",
        "print(\"cuDNN version       :\", torch.backends.cudnn.version())\n",
        "print(\"CUDA available      :\", torch.cuda.is_available())\n",
        "\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"Using device: {device}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "``` text\n",
        "================================================================================\n",
        "                        SIMPLE TRANSFORMER MODEL ARCHITECTURE\n",
        "                    Decoder-Only Autoregressive Text Generation\n",
        "================================================================================\n",
        "\n",
        "Model Configuration:\n",
        "┌─────────────────────────────────────────────────────────────────────────────┐\n",
        "│ Vocab Size: 28 (a-z + space + newline)  │  Context Length: 64 characters    │\n",
        "│ Embedding Dim: 128                       │  Attention Heads: 8               │\n",
        "│ Transformer Layers: 6                    │  Total Parameters: 1.2M           │\n",
        "└─────────────────────────────────────────────────────────────────────────────┘\n",
        "\n",
        "TRANSFORMER FLOW DIAGRAM:\n",
        "═══════════════════════════\n",
        "\n",
        "📝 INPUT TEXT\n",
        "┌─────────────────────────────────────────────────────────────────────────────┐\n",
        "│ Example: \"dogs are loyal and friendly animals that make great pets\"        │\n",
        "│ ⚡ Max Context: 64 characters at once                                       │\n",
        "└─────────────────────────────────────────────────────────────────────────────┘\n",
        "                                    ↓\n",
        "\n",
        "🔢 TOKENIZATION  \n",
        "┌─────────────────────────────────────────────────────────────────────────────┐\n",
        "│ Characters → Token IDs                                                      │\n",
        "│ [3,14,6,18,26,0,17,4,26,11,14,24,0,11,...]                               │\n",
        "└─────────────────────────────────────────────────────────────────────────────┘\n",
        "                                    ↓\n",
        "\n",
        "🎯 TOKEN EMBEDDING\n",
        "┌─────────────────────────────────────────────────────────────────────────────┐\n",
        "│ Token IDs → Dense Vectors (28 × 128)                                       │\n",
        "│ token_emb = TokenEmbedding(token_ids)                                       │\n",
        "└─────────────────────────────────────────────────────────────────────────────┘\n",
        "                                    +\n",
        "\n",
        "📍 POSITIONAL EMBEDDING\n",
        "┌─────────────────────────────────────────────────────────────────────────────┐\n",
        "│ Position indices → Dense Vectors (64 × 128)                                │\n",
        "│ pos_emb = PositionalEmbedding(positions)                                    │\n",
        "└─────────────────────────────────────────────────────────────────────────────┘\n",
        "                                    ↓\n",
        "\n",
        "➕ COMBINED EMBEDDINGS\n",
        "┌─────────────────────────────────────────────────────────────────────────────┐\n",
        "│ x = token_emb + pos_emb                                                     │\n",
        "│ Shape: (batch_size, seq_len, 128)                                          │\n",
        "└─────────────────────────────────────────────────────────────────────────────┘\n",
        "                                    ↓\n",
        "\n",
        "╔═════════════════════════════════════════════════════════════════════════════╗\n",
        "║                        🔄 TRANSFORMER BLOCK × 6 LAYERS                       ║\n",
        "╠═════════════════════════════════════════════════════════════════════════════╣\n",
        "║                                                                             ║\n",
        "║  ┌─────────────────────────────────────────────────────────────────────┐   ║\n",
        "║  │                         LAYER NORM 1                                │   ║\n",
        "║  │                Normalize input for attention                        │   ║\n",
        "║  └─────────────────────────────────────────────────────────────────────┘   ║\n",
        "║                                    ↓                                        ║\n",
        "║  ┌─────────────────────────────────────────────────────────────────────┐   ║\n",
        "║  │                 🎯 MULTI-HEAD ATTENTION (8 heads)                   │   ║\n",
        "║  │                                                                     │   ║\n",
        "║  │ • Q, K, V = Linear(x)                                               │   ║\n",
        "║  │ • Attention = softmax(QK^T/√d_k)V                                   │   ║\n",
        "║  │ • Head_size = 128/8 = 16                                            │   ║\n",
        "║  │ • Attention_Matrix = 64×64 (context_length²)                       │   ║\n",
        "║  │                                                                     │   ║\n",
        "║  │ Features:                                                           │   ║\n",
        "║  │ • Query, Key, Value projections                                     │   ║\n",
        "║  │ • Scaled dot-product attention                                      │   ║\n",
        "║  │ • Causal masking (64×64 lower triangular)                         │   ║\n",
        "║  │ • Each position attends to ≤64 previous positions                  │   ║\n",
        "║  │ • Concatenate & project heads                                       │   ║\n",
        "║  └─────────────────────────────────────────────────────────────────────┘   ║\n",
        "║                                    ↓                                        ║\n",
        "║  ┌─────────────────────────────────────────────────────────────────────┐   ║\n",
        "║  │                    ➕ RESIDUAL CONNECTION 1                          │   ║\n",
        "║  │                    x = x + attention(norm(x))                       │   ║\n",
        "║  └─────────────────────────────────────────────────────────────────────┘   ║\n",
        "║                                    ↓                                        ║\n",
        "║  ┌─────────────────────────────────────────────────────────────────────┐   ║\n",
        "║  │                         LAYER NORM 2                                │   ║\n",
        "║  │              Normalize input for feed-forward                       │   ║\n",
        "║  └─────────────────────────────────────────────────────────────────────┘   ║\n",
        "║                                    ↓                                        ║\n",
        "║  ┌─────────────────────────────────────────────────────────────────────┐   ║\n",
        "║  │                   🧠 FEED FORWARD NETWORK                           │   ║\n",
        "║  │                                                                     │   ║\n",
        "║  │ • FFN(x) = GELU(Linear1(x)) * Linear2                              │   ║\n",
        "║  │ • Hidden_dim = 4 × 128 = 512                                       │   ║\n",
        "║  │                                                                     │   ║\n",
        "║  │ Architecture:                                                       │   ║\n",
        "║  │ • Linear projection to 512 dims                                     │   ║\n",
        "║  │ • GELU activation function                                          │   ║\n",
        "║  │ • Linear projection back to 128 dims                               │   ║\n",
        "║  │ • Dropout for regularization                                        │   ║\n",
        "║  └─────────────────────────────────────────────────────────────────────┘   ║\n",
        "║                                    ↓                                        ║\n",
        "║  ┌─────────────────────────────────────────────────────────────────────┐   ║\n",
        "║  │                    ➕ RESIDUAL CONNECTION 2                          │   ║\n",
        "║  │                      x = x + ffn(norm(x))                          │   ║\n",
        "║  └─────────────────────────────────────────────────────────────────────┘   ║\n",
        "║                                                                             ║\n",
        "╚═════════════════════════════════════════════════════════════════════════════╝\n",
        "                                    ↓\n",
        "\n",
        "📊 FINAL LAYER NORM\n",
        "┌─────────────────────────────────────────────────────────────────────────────┐\n",
        "│ Normalize final transformer output                                          │\n",
        "└─────────────────────────────────────────────────────────────────────────────┘\n",
        "                                    ↓\n",
        "\n",
        "🎯 OUTPUT HEAD\n",
        "┌─────────────────────────────────────────────────────────────────────────────┐\n",
        "│ Linear projection to vocabulary size                                        │\n",
        "│ logits = Linear(x) → (batch, seq_len, 28)                                  │\n",
        "└─────────────────────────────────────────────────────────────────────────────┘\n",
        "                                    ↓\n",
        "\n",
        "📈 SOFTMAX & SAMPLING\n",
        "┌─────────────────────────────────────────────────────────────────────────────┐\n",
        "│ Convert logits to probabilities & sample next token                        │\n",
        "│ probs = softmax(logits / temperature)                                       │\n",
        "└─────────────────────────────────────────────────────────────────────────────┘\n",
        "                                    ↓\n",
        "\n",
        "📝 GENERATED TEXT\n",
        "┌─────────────────────────────────────────────────────────────────────────────┐\n",
        "│ Decode token IDs back to characters                                         │\n",
        "│                                                                             │\n",
        "│ Examples:                                                                   │\n",
        "│ 🐕 \"dogs\" → \"dogs come in many different breeds like gold\"                │\n",
        "│ 🐱 \"cats\" → \"cats communicate through meowing purring and\"                │\n",
        "│ 🐘 \"elephants\" → \"elephants live in family groups led by the oldest\"     │\n",
        "│ 🦇 \"bats\" → \"bats hibernate during winter when insects ar\"               │\n",
        "└─────────────────────────────────────────────────────────────────────────────┘\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Setup Character Vocabulary and Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocabulary: ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', ' ', '\\n']\n",
            "Vocabulary size: 28\n",
            "Original: 'hello\n",
            "world'\n",
            "Encoded: [7, 4, 11, 11, 14, 27, 22, 14, 17, 11, 3]\n",
            "Decoded: 'hello\n",
            "world'\n"
          ]
        }
      ],
      "source": [
        "# Create a-z vocabulary + space + newline\n",
        "chars = [chr(i) for i in range(ord('a'), ord('z') + 1)]  # a-z\n",
        "chars.append(' ')  # space\n",
        "chars.append('\\n')  # newline\n",
        "vocab_size = len(chars)\n",
        "print(f\"Vocabulary: {chars}\")\n",
        "print(f\"Vocabulary size: {vocab_size}\")\n",
        "\n",
        "# Create mappings\n",
        "stoi = {ch: i for i, ch in enumerate(chars)}\n",
        "itos = {i: ch for i, ch in enumerate(chars)}\n",
        "\n",
        "# Encoding and decoding functions\n",
        "def encode(s):\n",
        "    return [stoi[c] for c in s if c in stoi]\n",
        "\n",
        "def decode(l):\n",
        "    return ''.join([itos[i] for i in l])\n",
        "\n",
        "# Test encoding/decoding\n",
        "test_text = \"hello\\nworld\"\n",
        "encoded = encode(test_text)\n",
        "decoded = decode(encoded)\n",
        "print(f\"Original: '{test_text}'\")\n",
        "print(f\"Encoded: {encoded}\")\n",
        "print(f\"Decoded: '{decoded}'\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "##  Load animal training data from file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully loaded animal training data!\n",
            "Training text length: 32509 characters\n",
            "First 200 characters: 'dogs are loyal and friendly animals that make great pets for families with children dogs love to play fetch and go for walks in the park dogs need daily exercise and proper nutrition to stay healthy d'\n",
            "Last 100 characters: ...'zing geese play important roles in many ecosystems and have been domesticated for thousands of years'\n"
          ]
        }
      ],
      "source": [
        "# Load animal training data from file\n",
        "with open('animal_training_data.txt', 'r', encoding='utf-8') as f:\n",
        "    text = f.read().strip()\n",
        "print(\"Successfully loaded animal training data!\")\n",
        "\n",
        "# Verify the text contains only a-z, space, and newline characters\n",
        "allowed_chars = set(chars)\n",
        "clean_text = ''.join([c.lower() if c.lower() in allowed_chars else '' for c in text])\n",
        "\n",
        "print(f\"Training text length: {len(clean_text)} characters\")\n",
        "print(f\"First 200 characters: {repr(clean_text[:200])}\")  # Use repr to show newlines\n",
        "print(f\"Last 100 characters: ...{repr(clean_text[-100:])}\")\n",
        "\n",
        "# Store as text variable for compatibility\n",
        "text = clean_text\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Model Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model configuration:\n",
            "  Vocabulary size: 28\n",
            "  Block size: 64\n",
            "  Embedding dimension: 128\n",
            "  Number of heads: 8\n",
            "  Number of layers: 6\n",
            "  Dropout: 0.1\n"
          ]
        }
      ],
      "source": [
        "@dataclass\n",
        "class ModelConfig:\n",
        "    vocab_size: int = 28  # a-z + space + newline\n",
        "    block_size: int = 64   # context length\n",
        "    n_embd: int = 128      # embedding dimension\n",
        "    n_head: int = 8       # number of attention heads\n",
        "    n_layer: int = 6      # number of transformer blocks\n",
        "    dropout: float = 0.1  # dropout rate\n",
        "\n",
        "config = ModelConfig()\n",
        "print(f\"Model configuration:\")\n",
        "print(f\"  Vocabulary size: {config.vocab_size}\")\n",
        "print(f\"  Block size: {config.block_size}\")\n",
        "print(f\"  Embedding dimension: {config.n_embd}\")\n",
        "print(f\"  Number of heads: {config.n_head}\")\n",
        "print(f\"  Number of layers: {config.n_layer}\")\n",
        "print(f\"  Dropout: {config.dropout}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Transformer Components\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Transformer components defined successfully!\n"
          ]
        }
      ],
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        assert config.n_embd % config.n_head == 0\n",
        "        \n",
        "        self.n_head = config.n_head\n",
        "        self.n_embd = config.n_embd\n",
        "        self.head_size = config.n_embd // config.n_head\n",
        "        \n",
        "        # Query, Key, Value projections\n",
        "        self.qkv = nn.Linear(config.n_embd, 3 * config.n_embd)\n",
        "        self.proj = nn.Linear(config.n_embd, config.n_embd)\n",
        "        self.dropout = nn.Dropout(config.dropout)\n",
        "        \n",
        "        # Causal mask\n",
        "        self.register_buffer(\n",
        "            \"mask\", \n",
        "            torch.tril(torch.ones(config.block_size, config.block_size))\n",
        "            .view(1, 1, config.block_size, config.block_size)\n",
        "        )\n",
        "    \n",
        "    def forward(self, x):\n",
        "        B, T, C = x.size()  # batch, time, channels\n",
        "        \n",
        "        # Calculate Q, K, V\n",
        "        qkv = self.qkv(x)\n",
        "        q, k, v = qkv.split(self.n_embd, dim=2)\n",
        "        \n",
        "        # Reshape for multi-head attention\n",
        "        q = q.view(B, T, self.n_head, self.head_size).transpose(1, 2)  # (B, nh, T, hs)\n",
        "        k = k.view(B, T, self.n_head, self.head_size).transpose(1, 2)  # (B, nh, T, hs)\n",
        "        v = v.view(B, T, self.n_head, self.head_size).transpose(1, 2)  # (B, nh, T, hs)\n",
        "        \n",
        "        # Attention\n",
        "        att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(self.head_size))\n",
        "        att = att.masked_fill(self.mask[:, :, :T, :T] == 0, float('-inf'))\n",
        "        att = F.softmax(att, dim=-1)\n",
        "        att = self.dropout(att)\n",
        "        \n",
        "        # Apply attention to values\n",
        "        y = att @ v  # (B, nh, T, hs)\n",
        "        y = y.transpose(1, 2).contiguous().view(B, T, C)  # Reassemble heads\n",
        "        \n",
        "        # Output projection\n",
        "        y = self.proj(y)\n",
        "        return y\n",
        "\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(config.n_embd, 4 * config.n_embd),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(4 * config.n_embd, config.n_embd),\n",
        "            nn.Dropout(config.dropout),\n",
        "        )\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "\n",
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.ln1 = nn.LayerNorm(config.n_embd)\n",
        "        self.attn = MultiHeadAttention(config)\n",
        "        self.ln2 = nn.LayerNorm(config.n_embd)\n",
        "        self.ffn = FeedForward(config)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = x + self.attn(self.ln1(x))\n",
        "        x = x + self.ffn(self.ln2(x))\n",
        "        return x\n",
        "\n",
        "print(\"Transformer components defined successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Alternative\n",
        "\n",
        "### Flash attentions - increase FLOPS but reduce memory accesss\n",
        "output = F.scaled_dot_product_attention(q, k, v, attn_mask=mask, dropout_p=0.1)\n",
        "\n",
        "### Using Multiple AttentionHead\n",
        "```python\n",
        "class AttentionHead(nn.Module):\n",
        "    \"\"\"Single attention head with separate Q, K, V projections\"\"\"\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.head_size = config.n_embd // config.n_head\n",
        "        \n",
        "        # Separate Q, K, V projections instead of combined QKV\n",
        "        self.q_proj = nn.Linear(config.n_embd, self.head_size, bias=False)\n",
        "        self.k_proj = nn.Linear(config.n_embd, self.head_size, bias=False)  \n",
        "        self.v_proj = nn.Linear(config.n_embd, self.head_size, bias=False)\n",
        "        \n",
        "        self.dropout = nn.Dropout(config.dropout)\n",
        "        \n",
        "        # Causal mask\n",
        "        self.register_buffer(\n",
        "            \"mask\", \n",
        "            torch.tril(torch.ones(config.block_size, config.block_size))\n",
        "        )\n",
        "    \n",
        "    def forward(self, x):\n",
        "        B, T, C = x.size()\n",
        "        \n",
        "        # Separate Q, K, V projections\n",
        "        q = self.q_proj(x)  # (B, T, head_size)\n",
        "        k = self.k_proj(x)  # (B, T, head_size) \n",
        "        v = self.v_proj(x)  # (B, T, head_size)\n",
        "        \n",
        "        # Attention computation\n",
        "        att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(self.head_size))\n",
        "        att = att.masked_fill(self.mask[:T, :T] == 0, float('-inf'))\n",
        "        att = F.softmax(att, dim=-1)\n",
        "        att = self.dropout(att)\n",
        "        \n",
        "        # Apply attention to values\n",
        "        out = att @ v  # (B, T, head_size)\n",
        "        return out\n",
        "\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    \"\"\"Multi-head attention using separate AttentionHead instances\"\"\"\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        assert config.n_embd % config.n_head == 0\n",
        "        \n",
        "        self.n_head = config.n_head\n",
        "        self.n_embd = config.n_embd\n",
        "        self.head_size = config.n_embd // config.n_head\n",
        "        \n",
        "        # Create separate attention heads\n",
        "        self.heads = nn.ModuleList([\n",
        "            AttentionHead(config) for _ in range(config.n_head)\n",
        "        ])\n",
        "        \n",
        "        # Output projection\n",
        "        self.proj = nn.Linear(config.n_embd, config.n_embd)\n",
        "        self.dropout = nn.Dropout(config.dropout)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        # Run each head separately and concatenate results\n",
        "        head_outputs = [head(x) for head in self.heads]\n",
        "        out = torch.cat(head_outputs, dim=-1)  # (B, T, n_embd)\n",
        "        \n",
        "        # Output projection\n",
        "        out = self.proj(out)\n",
        "        return out\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Simple Transformer Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model created with 1,205,276 parameters\n",
            "Model size: 4.60 MB (fp32)\n"
          ]
        }
      ],
      "source": [
        "class SimpleTransformer(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        \n",
        "        # Token and position embeddings\n",
        "        self.token_embedding = nn.Embedding(config.vocab_size, config.n_embd)\n",
        "        self.position_embedding = nn.Embedding(config.block_size, config.n_embd)\n",
        "        \n",
        "        # Transformer blocks\n",
        "        self.blocks = nn.Sequential(\n",
        "            *[TransformerBlock(config) for _ in range(config.n_layer)]\n",
        "        )\n",
        "        \n",
        "        # Final layer norm and output head\n",
        "        self.ln_f = nn.LayerNorm(config.n_embd)\n",
        "        self.head = nn.Linear(config.n_embd, config.vocab_size)\n",
        "        \n",
        "        # Initialize weights\n",
        "        self.apply(self._init_weights)\n",
        "    \n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, nn.Linear):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "            if module.bias is not None:\n",
        "                torch.nn.init.zeros_(module.bias)\n",
        "        elif isinstance(module, nn.Embedding):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "    \n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.size()\n",
        "        assert T <= self.config.block_size, f\"Sequence too long: {T} > {self.config.block_size}\"\n",
        "        \n",
        "        # Create position indices\n",
        "        pos = torch.arange(0, T, dtype=torch.long, device=idx.device)\n",
        "        \n",
        "        # Embeddings\n",
        "        tok_emb = self.token_embedding(idx)  # (B, T, n_embd)\n",
        "        pos_emb = self.position_embedding(pos)  # (T, n_embd)\n",
        "        x = tok_emb + pos_emb  # (B, T, n_embd)\n",
        "        \n",
        "        # Transformer blocks\n",
        "        x = self.blocks(x)\n",
        "        x = self.ln_f(x)\n",
        "        \n",
        "        # Get logits\n",
        "        logits = self.head(x)  # (B, T, vocab_size)\n",
        "        \n",
        "        # Calculate loss if targets provided\n",
        "        loss = None\n",
        "        if targets is not None:\n",
        "            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1))\n",
        "        \n",
        "        return logits, loss\n",
        "    \n",
        "    def generate(self, idx, max_new_tokens, temperature=1.0):\n",
        "        \"\"\"\n",
        "        Generate new tokens given a context\n",
        "        \"\"\"\n",
        "        self.eval()\n",
        "        with torch.no_grad():\n",
        "            for _ in range(max_new_tokens):\n",
        "                # Crop context if too long\n",
        "                idx_cond = idx if idx.size(1) <= self.config.block_size else idx[:, -self.config.block_size:]\n",
        "                \n",
        "                # Get predictions\n",
        "                logits, _ = self(idx_cond)\n",
        "                logits = logits[:, -1, :] / temperature  # Get last token and scale\n",
        "                \n",
        "                # Sample from distribution\n",
        "                probs = F.softmax(logits, dim=-1)\n",
        "                idx_next = torch.multinomial(probs, num_samples=1)\n",
        "                \n",
        "                # Append to sequence\n",
        "                idx = torch.cat((idx, idx_next), dim=1)\n",
        "        \n",
        "        self.train()\n",
        "        return idx\n",
        "\n",
        "# Create model\n",
        "model = SimpleTransformer(config).to(device)\n",
        "\n",
        "# Count parameters\n",
        "n_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"Model created with {n_params:,} parameters\")\n",
        "print(f\"Model size: {n_params * 4 / 1024 / 1024:.2f} MB (fp32)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Data Preparation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Clean text length: 32509 characters\n",
            "Sample: 'dogs are loyal and friendly animals that make great pets for families with children dogs love to play fetch and go for walks in the park dogs need dai'\n",
            "Current vocabulary size: 28\n",
            "Vocabulary: ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', ' ', '\\n']\n",
            "Updated config vocabulary size: 28\n",
            "Data tensor shape: torch.Size([32509])\n",
            "Train data: 29258 tokens\n",
            "Val data: 3251 tokens\n",
            "\n",
            "Batch shapes: x=torch.Size([4, 64]), y=torch.Size([4, 64])\n",
            "Sample input: 'eat and humidity and can overheat easily\\n\\nguinea pigs are small '\n",
            "Sample target: 'at and humidity and can overheat easily\\n\\nguinea pigs are small d'\n"
          ]
        }
      ],
      "source": [
        "def get_batch(data, block_size, batch_size):\n",
        "    \"\"\"\n",
        "    Generate a batch of input-target pairs\n",
        "    \"\"\"\n",
        "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
        "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "    return x.to(device), y.to(device)\n",
        "\n",
        "# Prepare training data\n",
        "# Clean text to only include a-z, spaces, and newlines\n",
        "clean_text = ''.join([c.lower() if c.lower() in chars else '' for c in text])\n",
        "print(f\"Clean text length: {len(clean_text)} characters\")\n",
        "print(f\"Sample: {repr(clean_text[:150])}\")  # Use repr to show newlines\n",
        "\n",
        "# Verify vocabulary is complete\n",
        "print(f\"Current vocabulary size: {len(chars)}\")\n",
        "print(f\"Vocabulary: {chars}\")\n",
        "\n",
        "# Update config with actual vocabulary size\n",
        "config.vocab_size = len(chars)\n",
        "print(f\"Updated config vocabulary size: {config.vocab_size}\")\n",
        "\n",
        "# Encode the text\n",
        "data = torch.tensor(encode(clean_text), dtype=torch.long)\n",
        "print(f\"Data tensor shape: {data.shape}\")\n",
        "\n",
        "# Split into train/val\n",
        "n = len(data)\n",
        "train_data = data[:int(0.9*n)]\n",
        "val_data = data[int(0.9*n):]\n",
        "print(f\"Train data: {len(train_data)} tokens\")\n",
        "print(f\"Val data: {len(val_data)} tokens\")\n",
        "\n",
        "# Test batch generation\n",
        "batch_size = 4\n",
        "x, y = get_batch(train_data, config.block_size, batch_size)\n",
        "print(f\"\\nBatch shapes: x={x.shape}, y={y.shape}\")\n",
        "print(f\"Sample input: {repr(decode(x[0].tolist()))}\")\n",
        "print(f\"Sample target: {repr(decode(y[0].tolist()))}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model recreated with 1,205,276 parameters\n",
            "Starting training...\n",
            "iter    0: train loss 3.3642, val loss 3.1454\n",
            "iter  500: train loss 1.9557, val loss 1.9224\n",
            "iter 1000: train loss 1.2998, val loss 1.5871\n",
            "iter 1500: train loss 0.8808, val loss 1.5984\n",
            "iter 2000: train loss 0.6244, val loss 1.8584\n",
            "iter 2500: train loss 0.3946, val loss 2.0702\n",
            "iter 3000: train loss 0.3073, val loss 2.2184\n",
            "iter 3500: train loss 0.2929, val loss 2.4073\n",
            "iter 4000: train loss 0.2762, val loss 2.4973\n",
            "iter 4500: train loss 0.2370, val loss 2.6265\n",
            "iter 5000: train loss 0.2220, val loss 2.6438\n",
            "iter 5500: train loss 0.2147, val loss 2.6428\n",
            "iter 6000: train loss 0.2248, val loss 2.7149\n",
            "iter 6500: train loss 0.2120, val loss 2.7548\n",
            "iter 7000: train loss 0.1950, val loss 2.8730\n",
            "iter 7500: train loss 0.2074, val loss 2.8275\n",
            "iter 8000: train loss 0.2005, val loss 2.9106\n",
            "iter 8500: train loss 0.1908, val loss 2.9102\n",
            "iter 9000: train loss 0.1730, val loss 2.9331\n",
            "iter 9500: train loss 0.1891, val loss 2.9842\n",
            "iter 9999: train loss 0.1662, val loss 2.9289\n",
            "Training completed!\n"
          ]
        }
      ],
      "source": [
        "# Recreate model with updated config\n",
        "model = SimpleTransformer(config).to(device)\n",
        "n_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"Model recreated with {n_params:,} parameters\")\n",
        "\n",
        "# Training parameters\n",
        "learning_rate = 3e-4\n",
        "max_iters = 10000\n",
        "eval_interval = 500\n",
        "batch_size = 32\n",
        "\n",
        "# Optimizer\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "losses = []\n",
        "model.train()\n",
        "\n",
        "print(\"Starting training...\")\n",
        "for iter in range(max_iters):\n",
        "    # Get batch\n",
        "    x, y = get_batch(train_data, config.block_size, batch_size)\n",
        "    \n",
        "    # Forward pass\n",
        "    logits, loss = model(x, y)\n",
        "    \n",
        "    # Backward pass\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    # Track loss\n",
        "    losses.append(loss.item())\n",
        "    \n",
        "    # Print progress\n",
        "    if iter % eval_interval == 0 or iter == max_iters - 1:\n",
        "        # Evaluate on validation set\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            val_losses = []\n",
        "            for _ in range(100):  # 100 validation batches\n",
        "                x_val, y_val = get_batch(val_data, config.block_size, batch_size)\n",
        "                _, val_loss = model(x_val, y_val)\n",
        "                val_losses.append(val_loss.item())\n",
        "            val_loss = sum(val_losses) / len(val_losses)\n",
        "        \n",
        "        model.train()\n",
        "        print(f\"iter {iter:4d}: train loss {loss.item():.4f}, val loss {val_loss:.4f}\")\n",
        "\n",
        "print(\"Training completed!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Visualize Training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final training loss: 0.1662\n"
          ]
        }
      ],
      "source": [
        "# Plot training loss\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(losses)\n",
        "plt.title('Training Loss')\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('Loss')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Show final loss\n",
        "print(f\"Final training loss: {losses[-1]:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Text Generation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Animal Text Generation Examples:\n",
            "==================================================\n",
            "Prompt: 'dogs'\n",
            "Generated: 'dogs love to play fetch and go for walks in '\n",
            "------------------------------\n",
            "Prompt: 'cats'\n",
            "Generated: 'cats live in highly organized colonies with '\n",
            "------------------------------\n",
            "Prompt: 'birds'\n",
            "Generated: 'birds use their tongues to smell and taste th'\n",
            "------------------------------\n",
            "Prompt: 'fish'\n",
            "Generated: 'fish crabs mollusks and other aquatic creatu'\n",
            "------------------------------\n",
            "Prompt: 'elephants'\n",
            "Generated: 'elephants have large ears that help them cool dow'\n",
            "------------------------------\n",
            "Prompt: 'bats'\n",
            "Generated: 'bats live in colonies that can contain milli'\n",
            "------------------------------\n",
            "Prompt: 'bats'\n",
            "Generated: 'bats are wild canines that are ancestors of '\n",
            "------------------------------\n",
            "Prompt: 'geese'\n",
            "Generated: 'geese sharks have multiple rows of sharp teet'\n",
            "------------------------------\n",
            "Prompt: 'geese'\n",
            "Generated: 'geese and can overheat easily\n",
            "\n",
            "guinea pigs ar'\n",
            "------------------------------\n",
            "\n",
            "Same prompt with different temperatures:\n",
            "==================================================\n",
            "Temperature 0.5: 'dogs are sensitive to environmental ch'\n",
            "Temperature 1.0: 'dogs are small spiny mammals that can '\n",
            "Temperature 1.5: 'dogs are popular pets in some countrie'\n"
          ]
        }
      ],
      "source": [
        "def generate_text(prompt, max_tokens=50, temperature=1.0):\n",
        "    \"\"\"\n",
        "    Generate text given a prompt\n",
        "    \"\"\"\n",
        "    # Encode prompt\n",
        "    prompt_encoded = encode(prompt.lower())\n",
        "    if len(prompt_encoded) == 0:\n",
        "        prompt_encoded = [0]  # Start with first character if empty\n",
        "    \n",
        "    # Convert to tensor\n",
        "    context = torch.tensor(prompt_encoded, dtype=torch.long, device=device).unsqueeze(0)\n",
        "    \n",
        "    # Generate\n",
        "    generated = model.generate(context, max_tokens, temperature)\n",
        "    \n",
        "    # Decode\n",
        "    return decode(generated[0].tolist())\n",
        "\n",
        "# Test generation with different animal-related prompts\n",
        "prompts = [\"dogs\", \"cats\", \"birds\", \"fish\", \"elephants\",\"bats\",\"bats\",\"geese\",\"geese\"]\n",
        "\n",
        "print(\"Animal Text Generation Examples:\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "for prompt in prompts:\n",
        "    generated = generate_text(prompt, max_tokens=40, temperature=0.8)\n",
        "    print(f\"Prompt: '{prompt}'\")\n",
        "    print(f\"Generated: '{generated}'\")\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "# Try different temperatures with animal prompt\n",
        "print(\"\\nSame prompt with different temperatures:\")\n",
        "print(\"=\" * 50)\n",
        "prompt = \"dogs are\"\n",
        "for temp in [0.5, 1.0, 1.5]:\n",
        "    generated = generate_text(prompt, max_tokens=30, temperature=temp)\n",
        "    print(f\"Temperature {temp}: '{generated}'\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Model Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Architecture:\n",
            "  Total parameters: 1,205,276\n",
            "  Embedding parameters: 11,776\n",
            "  Transformer parameters: 1,189,632\n",
            "  Output head parameters: 3,584\n",
            "\n",
            "Next character probabilities for 'dogs are':\n",
            "  ' ': 1.000\n",
            "  'x': 0.000\n",
            "  'a': 0.000\n",
            "  't': 0.000\n",
            "  'i': 0.000\n",
            "  'u': 0.000\n",
            "  'o': 0.000\n",
            "  '\n",
            "': 0.000\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "SimpleTransformer(\n",
              "  (token_embedding): Embedding(28, 128)\n",
              "  (position_embedding): Embedding(64, 128)\n",
              "  (blocks): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (attn): MultiHeadAttention(\n",
              "        (qkv): Linear(in_features=128, out_features=384, bias=True)\n",
              "        (proj): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ln2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (ffn): FeedForward(\n",
              "        (net): Sequential(\n",
              "          (0): Linear(in_features=128, out_features=512, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=512, out_features=128, bias=True)\n",
              "          (3): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (attn): MultiHeadAttention(\n",
              "        (qkv): Linear(in_features=128, out_features=384, bias=True)\n",
              "        (proj): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ln2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (ffn): FeedForward(\n",
              "        (net): Sequential(\n",
              "          (0): Linear(in_features=128, out_features=512, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=512, out_features=128, bias=True)\n",
              "          (3): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (attn): MultiHeadAttention(\n",
              "        (qkv): Linear(in_features=128, out_features=384, bias=True)\n",
              "        (proj): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ln2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (ffn): FeedForward(\n",
              "        (net): Sequential(\n",
              "          (0): Linear(in_features=128, out_features=512, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=512, out_features=128, bias=True)\n",
              "          (3): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (attn): MultiHeadAttention(\n",
              "        (qkv): Linear(in_features=128, out_features=384, bias=True)\n",
              "        (proj): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ln2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (ffn): FeedForward(\n",
              "        (net): Sequential(\n",
              "          (0): Linear(in_features=128, out_features=512, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=512, out_features=128, bias=True)\n",
              "          (3): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (attn): MultiHeadAttention(\n",
              "        (qkv): Linear(in_features=128, out_features=384, bias=True)\n",
              "        (proj): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ln2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (ffn): FeedForward(\n",
              "        (net): Sequential(\n",
              "          (0): Linear(in_features=128, out_features=512, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=512, out_features=128, bias=True)\n",
              "          (3): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (attn): MultiHeadAttention(\n",
              "        (qkv): Linear(in_features=128, out_features=384, bias=True)\n",
              "        (proj): Linear(in_features=128, out_features=128, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ln2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "      (ffn): FeedForward(\n",
              "        (net): Sequential(\n",
              "          (0): Linear(in_features=128, out_features=512, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=512, out_features=128, bias=True)\n",
              "          (3): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (ln_f): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "  (head): Linear(in_features=128, out_features=28, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Analyze model components\n",
        "print(\"Model Architecture:\")\n",
        "print(f\"  Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "print(f\"  Embedding parameters: {model.token_embedding.weight.numel() + model.position_embedding.weight.numel():,}\")\n",
        "print(f\"  Transformer parameters: {sum(p.numel() for p in model.blocks.parameters()):,}\")\n",
        "print(f\"  Output head parameters: {model.head.weight.numel():,}\")\n",
        "\n",
        "# Test model on sample animal-related input\n",
        "sample_input = \"dogs are\"\n",
        "encoded_input = torch.tensor(encode(sample_input), dtype=torch.long, device=device).unsqueeze(0)\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    logits, _ = model(encoded_input)\n",
        "    probs = F.softmax(logits[0, -1], dim=-1)\n",
        "    \n",
        "print(f\"\\nNext character probabilities for '{sample_input}':\")\n",
        "top_k = 8\n",
        "top_probs, top_indices = torch.topk(probs, top_k)\n",
        "for i in range(top_k):\n",
        "    char = itos[top_indices[i].item()]\n",
        "    prob = top_probs[i].item()\n",
        "    print(f\"  '{char}': {prob:.3f}\")\n",
        "\n",
        "model.train()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
